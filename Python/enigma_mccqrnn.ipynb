{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Willem Bruin\n",
    "\n",
    "This Jupyter notebook applies the **MCCQRNN** model to provided FreeSurfer (FS)-derived MRI data.\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook performs the following steps:\n",
    "\n",
    "* Prepares FreeSurfer-derived MRI features from the ENIGMA-ANXIETY working group\n",
    "* Trains the MCCQRNN model on healthy controls using cross-validation\n",
    "* Applies the trained model to unseen patients\n",
    "* Computes uncertainty-adjusted Brain Age Gap (BAG) scores\n",
    "* Generates plots to evaluate model performance\n",
    "* Conducts occlusion sensitivity mapping\n",
    "\n",
    "---\n",
    "\n",
    "### Model Information\n",
    "\n",
    "The MCCQRNN model is described in:\n",
    "\n",
    "> Hahn, T., Ernsting, J., Winter, N. R., Holstein, V., Leenings, R., Beisemann, M., Fisch, L., Sarink, K., Emden, D., Opel, N., et al. (2022). *An uncertainty-aware, shareable, and transparent neural network architecture for brain-age modeling*. **Science Advances, 8**(1), eabg9471.\n",
    "> [https://www.science.org/doi/10.1126/sciadv.abg9471](https://www.science.org/doi/10.1126/sciadv.abg9471)\n",
    "\n",
    "The source code is available here:\n",
    "[https://github.com/wwu-mmll/uncertainty-brain-age](https://github.com/wwu-mmll/uncertainty-brain-age)\n",
    "\n",
    "---\n",
    "\n",
    "### Implementation Notes\n",
    "\n",
    "The version of the MCCQRNN model used in this project is copied to `/Scripts/MCCQRNN_Regressor.py` for usage.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from numpy.random import MT19937, RandomState, SeedSequence\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tp\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, train_test_split, cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import median_absolute_error, mean_absolute_error, explained_variance_score, mean_squared_error, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "import photonai\n",
    "from photonai.base import Hyperpipe, PipelineElement, PhotonRegistry\n",
    "from photonai.base.json_transformer import JsonTransformer\n",
    "from photonai.processing import ResultsHandler\n",
    "from photonai.processing.results_structure import MDBHyperpipe\n",
    "from photonai.optimization import FloatRange, Categorical, IntegerRange\n",
    "\n",
    "from Scripts.CustomCV import StratifiedGroupKFold, LeavePGroupsOut\n",
    "\n",
    "# Ensure warnings are imported if used\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('photonai version: {}'.format(photonai.__version__))\n",
    "print('tensorflow version: {}'.format(tf.__version__))\n",
    "print('tensorflow-probability version: {}'.format(tp.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this paramater to 1 to avoid printing annoying warnings (default=0)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "\n",
    "# Configure GPU's here\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; #\"0,1\" - Which devices to use. Let us use a single GPU\n",
    "\n",
    "# Optional - do NOT use any GPU's (only CPU)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of physical CPUs:\", os.cpu_count())\n",
    "\n",
    "tf.config.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ENIGMA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = '/data/wbbruin/Desktop/ENIGMA_ANXIETY/cross_disorder_data_v3'\n",
    "\n",
    "# This dataset contains duplicates of subjects that were included across multiple working groups (i.e. PD/SAD/GAD/SPH)\n",
    "pooled_df = pd.read_csv(os.path.join(SAVE_DIR, 'pooled_cross_disorder_data.csv'))\n",
    "\n",
    "# Here duplicates have been removed already. This dataset will be used for cross-disorder classifications\n",
    "pooled_df_no_duplicates = pd.read_csv(os.path.join(SAVE_DIR, 'pooled_cross_disorder_data_no_duplicates.csv'))\n",
    "\n",
    "pooled_df.shape, pooled_df_no_duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply age filter for adolescence: min = 10, max = 25 y/o\n",
    "\n",
    "min_age, max_age = 10, 25\n",
    "\n",
    "pooled_df = pooled_df.loc[(pooled_df.Age >= min_age) & (pooled_df.Age <= max_age)]\n",
    "\n",
    "pooled_df_no_duplicates = pooled_df_no_duplicates.loc[(pooled_df_no_duplicates.Age >= min_age) & \n",
    "                                                      (pooled_df_no_duplicates.Age <= max_age)]\n",
    "\n",
    "print(pooled_df.Age.min(), pooled_df.Age.max()) # Age range after filtering\n",
    "pooled_df.shape, pooled_df_no_duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df_no_duplicates.groupby(['WG', 'Dx']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels for FreeSurfer columns \n",
    "\n",
    "first_idx = np.where(pooled_df_no_duplicates.columns.values == 'L_bankssts_surfavg')[0][0]\n",
    "last_idx = np.where(pooled_df_no_duplicates.columns.values == 'ICV')[0][0]\n",
    "FS_cols = pooled_df_no_duplicates.columns.values[first_idx:last_idx+1]\n",
    "\n",
    "print(\"Total FS columns: {}\".format(len(FS_cols)))\n",
    "\n",
    "# Create a subset without global features (i.e. summarized measures over hemipsheres and ICV)\n",
    "global_FS_features = ['LSurfArea', 'RSurfArea', 'LThickness', 'RThickness', 'ICV']\n",
    "subset_mask = [f not in global_FS_features for f in FS_cols]\n",
    "FS_cols_wo_global = FS_cols[subset_mask]\n",
    "\n",
    "print(\"Total FS columns without global hemishpere measures and ICV: {}\".format(len(FS_cols_wo_global)))\n",
    "\n",
    "# Parse out different modalities (CT/CSA/SUBVOL)\n",
    "ct_mask = ['thick' in f for f in FS_cols_wo_global]\n",
    "csa_mask = ['surf' in f for f in FS_cols_wo_global]\n",
    "subcort_mask = ~np.array(ct_mask) & ~np.array(csa_mask)\n",
    "\n",
    "assert sum(ct_mask) + sum(csa_mask) + sum(subcort_mask) == len(FS_cols_wo_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude subjects with too many missing features for pooled data across WG\n",
    "\n",
    "def exclude_subjects_with_missing_features(df, FS_cols, completeness_threshold=0.75):\n",
    "    # Extract FS features\n",
    "    X = df[FS_cols].values\n",
    "\n",
    "    N_features = len(FS_cols)\n",
    "\n",
    "    # Create mask for subjects that have too many missing values\n",
    "    N_missing_per_subject = np.sum(np.isnan(X), axis=1)\n",
    "    p_missing_per_subject = N_missing_per_subject / float(N_features)\n",
    "    p_missing_inclusion_mask = (p_missing_per_subject < (1 - completeness_threshold))\n",
    "    n_missing_excluded = sum(~p_missing_inclusion_mask)\n",
    "\n",
    "    print(f\"{sum(N_missing_per_subject > 0)} of {len(N_missing_per_subject)} subjects have >=1 missing features\")\n",
    "    print(f\"{n_missing_excluded} subjects excluded with >{round((1 - completeness_threshold) * 100)}% missing features\")\n",
    "    print(df.loc[~p_missing_inclusion_mask].groupby(['WG', 'Dx']).size())\n",
    "    print()\n",
    "\n",
    "    df = df.loc[p_missing_inclusion_mask]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "pooled_df = exclude_subjects_with_missing_features(pooled_df, FS_cols_wo_global)\n",
    "\n",
    "# Do the same for cross-disorder data without duplicate entries\n",
    "pooled_df_no_duplicates = exclude_subjects_with_missing_features(pooled_df_no_duplicates, FS_cols_wo_global)\n",
    "\n",
    "pooled_df.shape, pooled_df_no_duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print demographics for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df_no_duplicates.Sex.unique(), # And separately for 0 = Males / 1 = females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df_no_duplicates.Dx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df_no_duplicates.groupby(['WG', 'Dx']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df_no_duplicates.groupby(['WG', 'Dx']).Sex.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df_no_duplicates.groupby(['WG', 'Dx']).Age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df_no_duplicates.groupby(['WG']).MultiSiteID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df_no_duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pooled_df_no_duplicates.MultiSiteID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df_no_duplicates.MultiSiteID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use healthy controls\n",
    "\n",
    "HC_df = pooled_df_no_duplicates.loc[pooled_df_no_duplicates.Dx == 0]\n",
    "HC_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_df.groupby('Sex').Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X, y and groups in scikit-compatable format\n",
    "\n",
    "# Check with experts: we now include global summary measures (ICV/total CT/SA). Is that OK?\n",
    "X = HC_df[FS_cols].to_numpy() # FS_cols_wo_global\n",
    "y = HC_df['Age'].to_numpy()\n",
    "groups = HC_df['MultiSiteID'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is % missing data\n",
    "np.isnan(X).sum() / X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    print(pooled_df_no_duplicates.groupby(['MultiSiteID', 'WG', 'Dx']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up cross-validation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_strategy(cv_df):\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=200)\n",
    "    le = LabelEncoder()\n",
    "    site_nums = le.fit_transform(cv_df.SiteID)\n",
    "    n_splits = len(cv_df.CV_test_iter.unique())\n",
    "\n",
    "    # Sort cv_df\n",
    "    sorted_cv_df = cv_df.sort_values(['SiteCount', 'CV_test_iter'], ascending=[False, False])\n",
    "    ordered_idx = sorted_cv_df.ID.values\n",
    "\n",
    "    for ii, (tr, tt) in enumerate(cv_splits):\n",
    "\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(cv_df))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices[ordered_idx],\n",
    "            marker=\"_\",\n",
    "            lw=10,\n",
    "            cmap=plt.cm.coolwarm,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Sites\n",
    "    ax.scatter(\n",
    "        range(len(cv_df)), [ii + 1.5] * len(cv_df), \n",
    "        c=site_nums[ordered_idx], \n",
    "        marker=\"_\", lw=10, cmap=plt.cm.prism\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 1) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.2],\n",
    "    #     xlim=[0, 500],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_strategy = 'StratifiedKFold'\n",
    "# cv_strategy = 'StratifiedGroupKFold'\n",
    "# cv_strategy = 'GroupKFold'\n",
    "\n",
    "# First we create bins for age using qcut. We use q=10, this corresponds to deciles\n",
    "age_binned, age_categories = pd.qcut(HC_df.Age, q=10, retbins=True, duplicates='drop')\n",
    "age_binned_codes = age_binned.cat.codes.astype(str)\n",
    "\n",
    "n_splits = 10\n",
    "random_state = 0\n",
    "\n",
    "# Save a dataframe for plotting/reporting\n",
    "cv_df = pd.DataFrame(columns=['ID'], data=np.arange(len(HC_df)))\n",
    "cv_df['Sex'] = HC_df.Sex.astype(int).values\n",
    "cv_df['Age'] = HC_df.Age.values\n",
    "cv_df['Age_bin'] = age_binned_codes.values\n",
    "cv_df['CV_test_iter'] = np.nan\n",
    "cv_df['labels_to_stratify'] = ''\n",
    "cv_df['SiteID'] = HC_df.MultiSiteID.values\n",
    "cv_df['SiteCount'] = cv_df.groupby('SiteID')['SiteID'].transform('count')\n",
    "\n",
    "if cv_strategy == 'StratifiedKFold':\n",
    "\n",
    "    # Here we will use age bins together with sex, site_ID and WG for stratification\n",
    "    labels_to_stratify = list(zip(HC_df.WG, HC_df.MultiSiteID, HC_df.Sex.astype(int).astype(str), \n",
    "                                  age_binned_codes))\n",
    "\n",
    "    labels_to_stratify = np.array(['_'.join(l) for l in labels_to_stratify])\n",
    "    cv_df['labels_to_stratify'] = labels_to_stratify\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    cv_splits = []\n",
    "    for i, (train, test) in enumerate(cv.split(y=labels_to_stratify, X=np.zeros_like(labels_to_stratify))):\n",
    "        cv_splits.append((train, test)) \n",
    "        cv_df.iloc[test, cv_df.columns.get_loc('CV_test_iter')] = i\n",
    "     \n",
    "    \n",
    "elif cv_strategy == 'StratifiedGroupKFold':\n",
    "\n",
    "    # Here we will use age_bins together with sex for stratification (but groups are kept seperate!)\n",
    "    labels_to_stratify = list(zip(HC_df.Sex.astype(int).astype(str), age_binned_codes))\n",
    "    labels_to_stratify = np.array(['_'.join(l) for l in labels_to_stratify])\n",
    "    cv_df['labels_to_stratify'] = labels_to_stratify\n",
    "    \n",
    "    cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    cv_splits = []\n",
    "    for i, (train, test) in enumerate(cv.split(y=labels_to_stratify, X=np.zeros_like(HC_df.MultiSiteID),\n",
    "                                               groups=HC_df.MultiSiteID)):\n",
    "        cv_splits.append((train, test)) \n",
    "        cv_df.iloc[test, cv_df.columns.get_loc('CV_test_iter')] = i\n",
    "\n",
    "        \n",
    "elif cv_strategy == 'GroupKFold':\n",
    "    \n",
    "    cv = GroupKFold(n_splits=n_splits)\n",
    "    labels_to_stratify = HC_df.MultiSiteID.values # This will be passed to Hyperpipe as 'groups'\n",
    "    cv_df['labels_to_stratify'] = labels_to_stratify \n",
    "    \n",
    "    cv_splits = []\n",
    "    for i, (train, test) in enumerate(cv.split(y=np.zeros_like(HC_df.MultiSiteID), \n",
    "                                               X=np.zeros_like(HC_df.MultiSiteID),\n",
    "                                               groups=HC_df.MultiSiteID)):\n",
    "        cv_splits.append((train, test)) \n",
    "        cv_df.iloc[test, cv_df.columns.get_loc('CV_test_iter')] = i\n",
    "\n",
    "\n",
    "# Visualize CV strategy\n",
    "plot_cv_strategy(cv_df)\n",
    "\n",
    "# Summarize info on test set\n",
    "test_set_info = cv_df.copy().groupby('CV_test_iter')['Age', 'Sex'].mean().reset_index()\n",
    "for i in cv_df.CV_test_iter.unique():\n",
    "    test_set_info.loc[test_set_info.CV_test_iter == i, 'size'] = cv_df.loc[cv_df.CV_test_iter == i].shape[0]\n",
    "    test_set_info.loc[test_set_info.CV_test_iter == i, 'n_sites'] = len(cv_df.loc[cv_df.CV_test_iter == i].SiteID.unique())\n",
    "    test_set_info.loc[test_set_info.CV_test_iter == i, 'sites'] = ' '.join(cv_df.loc[cv_df.CV_test_iter == i].SiteID.unique())\n",
    "    \n",
    "test_set_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cv_df.CV_test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up MCCQRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = os.getcwd()\n",
    "custom_elements_folder = os.path.join(base_folder, 'Scripts')\n",
    "\n",
    "# Remove previously registered elements\n",
    "registry = PhotonRegistry(custom_elements_folder=custom_elements_folder)\n",
    "registry.delete('MccModel')\n",
    "registry.delete('IterativeImputerTrees')\n",
    "\n",
    "for path in os.listdir(custom_elements_folder):\n",
    "    if path == '__pycache__':\n",
    "        shutil.rmtree(os.path.join(custom_elements_folder, path))\n",
    "    elif path == 'CustomElements.json':\n",
    "        os.remove(os.path.join(custom_elements_folder, path))\n",
    "        \n",
    "cache_dir = os.path.join(base_folder, 'cache')\n",
    "if os.path.isdir(cache_dir):\n",
    "    shutil.rmtree(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = PhotonRegistry(custom_elements_folder=custom_elements_folder)\n",
    "registry.register(photon_name='MccModel',\n",
    "                  class_str='MCCQRNN_Regressor.MCCQRNN_Regressor', element_type='Estimator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check registration\n",
    "\n",
    "registry.info('MccModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = PhotonRegistry(custom_elements_folder=custom_elements_folder)\n",
    "registry.register(photon_name='MICE_IterativeImputer',\n",
    "                  class_str='MICE_IterativeImputer.MICE_IterativeImputer', element_type='Transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check registration\n",
    "\n",
    "registry.info('MICE_IterativeImputer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define pipeline\n",
    "\n",
    "my_pipe = Hyperpipe('MCC_' + cv_strategy,\n",
    "                    inner_cv = cv,                  \n",
    "                    metrics=['mean_absolute_error', 'mean_squared_error', \n",
    "                             'pearson_correlation', 'explained_variance'],\n",
    "                    best_config_metric='mean_absolute_error',\n",
    "                    cache_folder='./cache/',\n",
    "                    eval_final_performance=False,\n",
    "                    verbosity=2,\n",
    "                   )\n",
    "\n",
    "my_pipe += PipelineElement('StandardScaler')\n",
    "\n",
    "# my_pipe += PipelineElement('SimpleImputer')\n",
    "my_pipe += PipelineElement('MICE_IterativeImputer')\n",
    "\n",
    "my_pipe += PipelineElement('MccModel')\n",
    "\n",
    "my_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comment if already ran\n",
    "\n",
    "my_pipe.fit(data=X, targets=y, groups=labels_to_stratify) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fitted model, predictions, and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_RESULTS = True\n",
    "print(cv_strategy)\n",
    "\n",
    "path_mask = ['_'.join(['MCC', cv_strategy, 'results']) in path for path in os.listdir('.')]\n",
    "result_dir_name = np.array(os.listdir('.'))[path_mask][0]\n",
    "result_dir_path = os.path.join('.', result_dir_name)\n",
    "\n",
    "if LOAD_RESULTS:\n",
    "    # Use previously stored data\n",
    "    result_json_path = os.path.join(result_dir_path, 'photon_result_file.json')\n",
    "    json_file = json.load(open(result_json_path, 'r'))\n",
    "\n",
    "    results = MDBHyperpipe.from_document(json_file)\n",
    "    handler = ResultsHandler(results)\n",
    "\n",
    "    # Load optimal Hyperpipe\n",
    "    model_photon_path = os.path.join(result_dir_path, 'photon_best_model.photon')\n",
    "    my_pipe = Hyperpipe.load_optimum_pipe(model_photon_path)\n",
    "else:\n",
    "    # Continue working with the results directly now\n",
    "    handler = my_pipe.results_handler\n",
    "    results = handler.results\n",
    "\n",
    "print(result_dir_path)\n",
    "my_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(y_true, y_pred):\n",
    "    return np.corrcoef(y_true, y_pred)[0][1]\n",
    "\n",
    "\n",
    "def calculate_adj_BAG(df):\n",
    "    \"\"\"\n",
    "    Calculate the uncertainty adjusted Brain-Age-Gap.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing 'y_pred', 'y_true', and 'std_aleatory_epistemic' columns.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of adjusted BAG HC scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert np.all(df['y_pred'] == df['median_aleatory_epistemic'])\n",
    "    \n",
    "    adj_BAG = ((df['y_pred'] - df['y_true']) / df['std_aleatory_epistemic']).values\n",
    "                  \n",
    "    return adj_BAG\n",
    "\n",
    "\n",
    "def calculate_metrics_across_folds(predictions_df):\n",
    "    \n",
    "    metrics_df = pd.DataFrame({'fold' : np.unique(predictions_df.fold.unique())})\n",
    "    for i_fold in metrics_df.fold.values:\n",
    "\n",
    "        y_pred_fold = predictions_df.loc[predictions_df.fold == i_fold].y_pred.values\n",
    "        y_true_fold = predictions_df.loc[predictions_df.fold == i_fold].y_true.values\n",
    "\n",
    "        metrics_df.loc[metrics_df.fold == i_fold,\n",
    "                       'N'] = sum(predictions_df.fold == i_fold)\n",
    "        metrics_df.loc[metrics_df.fold == i_fold, \n",
    "                       'MAE'] = mean_absolute_error(y_true=y_true_fold, y_pred=y_pred_fold)\n",
    "        metrics_df.loc[metrics_df.fold == i_fold, \n",
    "                       'MedianAE'] = median_absolute_error(y_true=y_true_fold, y_pred=y_pred_fold)\n",
    "        metrics_df.loc[metrics_df.fold == i_fold, \n",
    "                       'MSE'] = mean_squared_error(y_true=y_true_fold, y_pred=y_pred_fold)\n",
    "        metrics_df.loc[metrics_df.fold == i_fold, \n",
    "                       'r'] = pearson_correlation(y_true=y_true_fold, y_pred=y_pred_fold)\n",
    "        metrics_df.loc[metrics_df.fold == i_fold, \n",
    "                       'EV'] = explained_variance_score(y_true=y_true_fold, y_pred=y_pred_fold)\n",
    "        metrics_df.loc[metrics_df.fold == i_fold, \n",
    "                       'rs'] = stats.spearmanr(y_true_fold, y_pred_fold)[0]\n",
    "\n",
    "    mean, std = metrics_df.mean().values[2:].round(2), metrics_df.std().values[2:].round(2)\n",
    "    metrics_df.loc[len(metrics_df)] = np.append(['mean', ''], mean)\n",
    "    metrics_df.loc[len(metrics_df)] = np.append(['std', ''], std)\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse predictions and performance metrics for healthy controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all predictions across CV iterations into a DataFrame (for healthy controls)\n",
    "MCC_results_df = pd.DataFrame(handler.get_best_config_inner_fold_predictions())\n",
    "\n",
    "# Extract folds used by photon-ai\n",
    "inner_folds_preds = handler.get_best_config_inner_fold_predictions()\n",
    "\n",
    "# Verify if the predictions match the expected values\n",
    "assert np.all(MCC_results_df.y_true.values == np.array(inner_folds_preds['y_true'])), \"Mismatch in y_true values with inner fold predictions\"\n",
    "assert np.all(MCC_results_df.y_true.values == y), \"Mismatch in y_true values with y\"\n",
    "assert np.all(MCC_results_df.y_true.values == HC_df.Age), \"Mismatch in y_true values with HC_df.Age\"\n",
    "\n",
    "# Ensure y_pred is not corrected for aleatory uncertainty by default\n",
    "assert np.all(MCC_results_df['y_pred'] == MCC_results_df['median_noAleatory_epistemic']), \"y_pred is not equal to median_noAleatory_epistemic\"\n",
    "\n",
    "# Replace y_pred with 'median_aleatory_epistemic'\n",
    "MCC_results_df['y_pred'] = MCC_results_df['median_aleatory_epistemic']\n",
    "\n",
    "# Calculate and add the adjusted BAG score\n",
    "MCC_results_df['adj_BAG'] = calculate_adj_BAG(MCC_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with metrics OVER folds and ACROSS folds.\n",
    "\n",
    "metrics_df = calculate_metrics_across_folds(MCC_results_df)\n",
    "metrics_df.to_csv(os.path.join(result_dir_path, 'metrics_on_training_HC.csv'))\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now provide predictions for patients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for patients\n",
    "PT_df = pooled_df_no_duplicates.loc[pooled_df_no_duplicates.Dx == 1]\n",
    "\n",
    "# Extract X, y, and groups in scikit-compatible format\n",
    "X_pt = PT_df[FS_cols].to_numpy()\n",
    "y_pt = PT_df['Age'].to_numpy()\n",
    "groups_pt = PT_df['MultiSiteID'].to_numpy()\n",
    "\n",
    "# Print information about the dataset\n",
    "print(f\"Total samples: {pooled_df_no_duplicates.shape[0]}, Patients: {PT_df.shape[0]}, Healthy controls: {HC_df.shape[0]}\")\n",
    "print(f\"Total sites: {len(pooled_df_no_duplicates.MultiSiteID.unique())}, Patient sites: {len(PT_df.MultiSiteID.unique())}, Healthy control sites: {len(HC_df.MultiSiteID.unique())}\")\n",
    "\n",
    "# Path for patient predictions\n",
    "predictions_patients_csv_path = os.path.join(result_dir_path, 'predictions_patients.csv') # test\n",
    "\n",
    "# Load or generate predictions for patients\n",
    "if os.path.exists(predictions_patients_csv_path):\n",
    "    predictions_patients_df = pd.read_csv(predictions_patients_csv_path)\n",
    "else:\n",
    "    y_pred_patients = my_pipe.predict(X_pt)\n",
    "    \n",
    "    # Store predictions for patients\n",
    "    predictions_patients_df = pd.DataFrame(y_pred_patients)\n",
    "    assert np.all(predictions_patients_df['y_pred'] == predictions_patients_df['median_noAleatory_epistemic']), \"y_pred is not equal to median_noAleatory_epistemic\"\n",
    "    \n",
    "    predictions_patients_df['y_pred'] = predictions_patients_df['median_aleatory_epistemic']\n",
    "    predictions_patients_df['y_true'] = y_pt\n",
    "    predictions_patients_df.to_csv(predictions_patients_csv_path, index=False)\n",
    "\n",
    "# Verify y_pred and median_aleatory_epistemic match\n",
    "assert np.all(predictions_patients_df['median_aleatory_epistemic'] == predictions_patients_df['y_pred']), \"Mismatch between median_aleatory_epistemic and y_pred\"\n",
    "\n",
    "# Calculate and add the adjusted BAG score\n",
    "predictions_patients_df['adj_BAG'] = calculate_adj_BAG(predictions_patients_df)\n",
    "\n",
    "print(predictions_patients_df['adj_BAG'].mean())\n",
    "predictions_patients_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and store metrics for patients (no cross-validation folds, so calculate over all patients)\n",
    "\n",
    "# Extract true and predicted values\n",
    "y_true = predictions_patients_df.y_true\n",
    "y_pred = predictions_patients_df.y_pred\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)\n",
    "medae = median_absolute_error(y_true=y_true, y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "pearson_corr = pearson_correlation(y_true=y_true, y_pred=y_pred)\n",
    "evs = explained_variance_score(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Median Absolute Error (MedAE): {medae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr}\")\n",
    "print(f\"Explained Variance Score (EVS): {evs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape, PT_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create plots (four panels) for Figure 1: model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# Plot performance for healthy controls (1A)\n",
    "\n",
    "# Use scatterplot to color individual datapoints using 'hue'\n",
    "g_scatter = sns.scatterplot(data=MCC_results_df, x=\"y_true\", y=\"y_pred\", \n",
    "                            hue = MCC_results_df.adj_BAG,\n",
    "                            palette = sns.color_palette(\"PuOr_r\", as_cmap=True)\n",
    "                            )\n",
    "\n",
    "colors = g_scatter.collections[0].properties()['facecolor']\n",
    "plt.close()\n",
    "\n",
    "\n",
    "min_, max_ = np.floor(MCC_results_df.y_true.min()), np.ceil(MCC_results_df.y_true.max())\n",
    "g = sns.jointplot(data=MCC_results_df, x=\"y_true\", y=\"y_pred\", \n",
    "                  x_jitter=0,\n",
    "                  kind=\"reg\",\n",
    "                  xlim=(min_ - 0.5 , max_ + 0.5),\n",
    "                  joint_kws = {'scatter_kws' : dict(alpha=0.5, s=15),\n",
    "                               'line_kws' : dict(color=\"darkred\", alpha=0.5)},\n",
    "                  marginal_kws={'color': 'darkgrey',\n",
    "                               }\n",
    "                 )\n",
    "\n",
    "# Clear the axes containing the scatter plot\n",
    "g.ax_joint.collections[0].set_visible(False)\n",
    "\n",
    "#Plot each individual point separately\n",
    "for i,row in enumerate(MCC_results_df[['y_true', 'y_pred']].values):\n",
    "    g.ax_joint.plot(row[0], row[1], color=colors[i], marker='o', zorder=0, alpha=0.9)\n",
    "    \n",
    "\n",
    "# Plot text: avearge r2 (EV), pearson r, and MAE\n",
    "rp_str = str(np.round(float(metrics_df.loc[metrics_df.fold == 'mean']['r'].values[0]), 2)).ljust(4 , '0')\n",
    "EV_str = str(np.round(float(metrics_df.loc[metrics_df.fold == 'mean']['EV'].values[0]), 2)).ljust(4 , '0')\n",
    "MAE_str = str(np.round(float(metrics_df.loc[metrics_df.fold == 'mean']['MAE'].values[0]), 2)).ljust(4 , '0')\n",
    "rs_str = str(np.round(float(metrics_df.loc[metrics_df.fold == 'mean']['rs'].values[0]), 2)).ljust(4 , '0')\n",
    "\n",
    "# g.fig.text\n",
    "g.fig.text(0.15, 0.80, \n",
    "       f'$r_p$ = {rp_str}\\n'\n",
    "       f'$r_s$ = {rs_str}\\n'\n",
    "       f'EV = {EV_str}\\n'\n",
    "       f'MAE = {MAE_str}\\n',\n",
    "       va = 'top',\n",
    "       fontsize=10)\n",
    "\n",
    "g.set_axis_labels(xlabel='Chronological Age', ylabel='Predicted Brain Age', fontsize=10)\n",
    "g.fig.set_figwidth(8)\n",
    "g.fig.set_figheight(6)\n",
    "\n",
    "g.savefig(os.path.join(result_dir_path, 'Figure_1A_performance_on_training_HC.png'))\n",
    "\n",
    "# Extract ylim and yticks so we can set them in other figure\n",
    "ax = g.fig.gca()\n",
    "ylim = ax.get_ylim()\n",
    "yticks = ax.get_yticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance for patients (1B)\n",
    "\n",
    "# Use scatterplot to color individual datapoints using 'hue'\n",
    "g_scatter = sns.scatterplot(data=predictions_patients_df, x=\"y_true\", y=\"y_pred\", \n",
    "                            hue = predictions_patients_df.adj_BAG,\n",
    "                            palette = sns.color_palette(\"PuOr_r\", as_cmap=True)\n",
    "                            )\n",
    "\n",
    "colors = g_scatter.collections[0].properties()['facecolor']\n",
    "plt.close()\n",
    "\n",
    "\n",
    "min_, max_ = np.floor(predictions_patients_df.y_true.min()), np.ceil(predictions_patients_df.y_true.max())\n",
    "\n",
    "g = sns.jointplot(data=predictions_patients_df, x=\"y_true\", y=\"y_pred\", \n",
    "                  x_jitter=0,\n",
    "                  kind=\"reg\",\n",
    "                  xlim=(min_ - 0.5 , max_ + 0.5),\n",
    "                  ylim=ylim,\n",
    "                  joint_kws = {'scatter_kws' : dict(alpha=0.5, s=15),\n",
    "                               'line_kws' : dict(color=\"darkred\", alpha=0.5)},\n",
    "                  marginal_kws={'color': 'darkgrey',\n",
    "                               }\n",
    "                 )\n",
    "\n",
    "# Clear the axes containing the scatter plot\n",
    "g.ax_joint.collections[0].set_visible(False)\n",
    "\n",
    "#Plot each individual point separately\n",
    "for i,row in enumerate(predictions_patients_df[['y_true', 'y_pred']].values):\n",
    "    g.ax_joint.plot(row[0], row[1], color=colors[i], marker='o', zorder=0, alpha=0.9)\n",
    "    \n",
    "\n",
    "# Plot text: avearge r2 (EV), pearson r, and MAE\n",
    "rp_str = str(np.round(pearson_correlation(y_true=predictions_patients_df.y_true, \n",
    "                                         y_pred=predictions_patients_df.y_pred), 2)).ljust(4 , '0')\n",
    "rs_str = str(np.round(stats.spearmanr(predictions_patients_df.y_true, \n",
    "                                      predictions_patients_df.y_pred), 2)[0]).ljust(4 , '0')\n",
    "EV_str = str(np.round(explained_variance_score(y_true=predictions_patients_df.y_true, \n",
    "                                               y_pred=predictions_patients_df.y_pred), 2)).ljust(4 , '0')\n",
    "MAE_str = str(np.round(mean_absolute_error(y_true=predictions_patients_df.y_true, \n",
    "                                           y_pred=predictions_patients_df.y_pred), 2)).ljust(4 , '0')\n",
    "\n",
    "# g.fig.text\n",
    "g.fig.text(0.15, 0.80, \n",
    "       f'$r_p$ = {rp_str}\\n'\n",
    "       f'$r_s$ = {rs_str}\\n'\n",
    "       f'EV = {EV_str}\\n'\n",
    "       f'MAE = {MAE_str}\\n',\n",
    "       va = 'top',\n",
    "       fontsize=10)\n",
    "\n",
    "g.set_axis_labels(xlabel='Chronological Age', ylabel='Predicted Brain Age', fontsize=10)\n",
    "g.fig.set_figwidth(8)\n",
    "g.fig.set_figheight(6)\n",
    "\n",
    "g.savefig(os.path.join(result_dir_path, 'Figure_1B_performance_on_testing_patients.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot BAG for healthy controls (1C)\n",
    "\n",
    "# Calculate adjusted and unadjusted BAG\n",
    "adj_BAG_HC = ((MCC_results_df['y_pred'] - MCC_results_df['y_true']) / MCC_results_df['std_aleatory_epistemic']).values\n",
    "unadj_BAG_HC = (MCC_results_df['y_pred'] - MCC_results_df['y_true'])\n",
    "\n",
    "# Print Pearson and Spearman correlations\n",
    "print('Pearson correlations:')\n",
    "print('adj', stats.pearsonr(np.array(MCC_results_df['y_true']), adj_BAG_HC))\n",
    "print('unadj', stats.pearsonr(np.array(MCC_results_df['y_true']), unadj_BAG_HC))\n",
    "print('Spearman correlations:')\n",
    "print('adj', stats.spearmanr(np.array(MCC_results_df['y_true']), adj_BAG_HC))\n",
    "print('unadj', stats.spearmanr(np.array(MCC_results_df['y_true']), unadj_BAG_HC))\n",
    "\n",
    "# Create the figure and axes with desired width and height\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "\n",
    "# Copy DataFrame for plotting\n",
    "tmp_df = MCC_results_df.copy()\n",
    "tmp_df['adj_BAG'] = adj_BAG_HC\n",
    "tmp_df['unadj_BAG'] = unadj_BAG_HC\n",
    "\n",
    "# Define min and max limits for x-axis\n",
    "min_, max_ = np.floor(tmp_df.y_true.min()), np.ceil(tmp_df.y_true.max())\n",
    "\n",
    "# Plot unadjusted BAG\n",
    "sns.regplot(x='y_true', y='unadj_BAG', data=tmp_df, fit_reg=True, ax=ax,\n",
    "            x_jitter=.0,\n",
    "            line_kws=dict(alpha=0.75),\n",
    "            scatter_kws=dict(alpha=0.2, s=15), label='Unadjusted')\n",
    "\n",
    "slope_unadj, intercept_unadj, r_value, p_value, std_err = stats.linregress(x=ax.get_lines()[0].get_xdata(),\n",
    "                                                                           y=ax.get_lines()[0].get_ydata())\n",
    "slope_unadj = str(np.round(slope_unadj, 2))\n",
    "intercept_unadj = str(np.round(intercept_unadj, 2))\n",
    "\n",
    "# Plot adjusted BAG\n",
    "sns.regplot(x='y_true', y='adj_BAG', data=tmp_df, fit_reg=True, ax=ax,\n",
    "            x_jitter=.0,\n",
    "            line_kws=dict(alpha=0.75),\n",
    "            scatter_kws=dict(alpha=0.2, s=15), label='Uncertainty Adjusted')\n",
    "\n",
    "slope_adj, intercept_adj, r_value, p_value, std_err = stats.linregress(x=ax.get_lines()[1].get_xdata(),\n",
    "                                                                       y=ax.get_lines()[1].get_ydata())\n",
    "slope_adj = str(np.round(slope_adj, 2))\n",
    "intercept_adj = str(np.round(intercept_adj, 2))\n",
    "\n",
    "# Set labels and limits\n",
    "ax.set(ylabel='Brain Age Gap', xlabel='Chronological Age')\n",
    "ax.set_xlim(min_ - 0.5, max_ + 0.5)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Calculate and format correlation values\n",
    "rp_unadj_str = str(np.round(stats.pearsonr(tmp_df.y_true, tmp_df.unadj_BAG)[0], 2))\n",
    "rs_unadj_str = str(np.round(stats.spearmanr(tmp_df.y_true, tmp_df.unadj_BAG)[0], 2))\n",
    "\n",
    "rp_adj_str = str(np.round(stats.pearsonr(tmp_df.y_true, tmp_df.adj_BAG)[0], 2))\n",
    "rs_adj_str = str(np.round(stats.spearmanr(tmp_df.y_true, tmp_df.adj_BAG)[0], 2))\n",
    "\n",
    "# Add text boxes with regression info\n",
    "fig.text(0.15, 0.25,\n",
    "         'Unadjusted \\n'\n",
    "         f'y = {intercept_unadj} + {slope_unadj}x\\n'\n",
    "         f'$r_p$ = {rp_unadj_str}\\n'\n",
    "         f'$r_s$ = {rs_unadj_str}\\n',\n",
    "         va='top',\n",
    "         fontsize=10)\n",
    "\n",
    "fig.text(0.35, 0.25,\n",
    "         'Adjusted \\n'\n",
    "         f'y = {intercept_adj} + {slope_adj}x\\n'\n",
    "         f'$r_p$ = {rp_adj_str}\\n'\n",
    "         f'$r_s$ = {rs_adj_str}\\n',\n",
    "         va='top',\n",
    "         fontsize=10)\n",
    "\n",
    "# Set fontsize for labels\n",
    "ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig(os.path.join(result_dir_path, 'Figure_1C_BAG_for_healthy_controls.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot BAG for patients (1D)\n",
    "\n",
    "# Calculate adjusted and unadjusted BAG\n",
    "adj_BAG_pred_patients = ((predictions_patients_df['y_pred'] - predictions_patients_df['y_true']) / predictions_patients_df['std_aleatory_epistemic']).values\n",
    "unadj_BAG_pred_patients = (predictions_patients_df['y_pred'] - predictions_patients_df['y_true'])\n",
    "\n",
    "# Print Pearson and Spearman correlations\n",
    "print('Pearson correlations:')\n",
    "print('adj', stats.pearsonr(np.array(predictions_patients_df['y_true']), adj_BAG_pred_patients))\n",
    "print('unadj', stats.pearsonr(np.array(predictions_patients_df['y_true']), unadj_BAG_pred_patients))\n",
    "print('Spearman correlations:')\n",
    "print('adj', stats.spearmanr(np.array(predictions_patients_df['y_true']), adj_BAG_pred_patients))\n",
    "print('unadj', stats.spearmanr(np.array(predictions_patients_df['y_true']), unadj_BAG_pred_patients))\n",
    "\n",
    "# Create the figure and axes with desired width and height\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "\n",
    "# Copy DataFrame for plotting\n",
    "tmp_df = predictions_patients_df.copy()\n",
    "tmp_df['adj_BAG'] = adj_BAG_pred_patients\n",
    "tmp_df['unadj_BAG'] = unadj_BAG_pred_patients\n",
    "\n",
    "# Define min and max limits for x-axis\n",
    "min_, max_ = np.floor(tmp_df.y_true.min()), np.ceil(tmp_df.y_true.max())\n",
    "\n",
    "# Plot unadjusted BAG\n",
    "sns.regplot(x='y_true', y='unadj_BAG', data=tmp_df, fit_reg=True, ax=ax,\n",
    "            x_jitter=.0,\n",
    "            line_kws=dict(alpha=0.75),\n",
    "            scatter_kws=dict(alpha=0.2, s=15), label='Unadjusted')\n",
    "\n",
    "slope_unadj, intercept_unadj, r_value, p_value, std_err = stats.linregress(x=ax.get_lines()[0].get_xdata(),\n",
    "                                                                           y=ax.get_lines()[0].get_ydata())\n",
    "slope_unadj = str(np.round(slope_unadj, 2))\n",
    "intercept_unadj = str(np.round(intercept_unadj, 2))\n",
    "\n",
    "# Plot adjusted BAG\n",
    "sns.regplot(x='y_true', y='adj_BAG', data=tmp_df, fit_reg=True, ax=ax,\n",
    "            x_jitter=.0,\n",
    "            line_kws=dict(alpha=0.75),\n",
    "            scatter_kws=dict(alpha=0.2, s=15), label='Uncertainty Adjusted')\n",
    "\n",
    "slope_adj, intercept_adj, r_value, p_value, std_err = stats.linregress(x=ax.get_lines()[1].get_xdata(),\n",
    "                                                                       y=ax.get_lines()[1].get_ydata())\n",
    "slope_adj = str(np.round(slope_adj, 2))\n",
    "intercept_adj = str(np.round(intercept_adj, 2))\n",
    "\n",
    "# Set labels and limits\n",
    "ax.set(ylabel='Brain Age Gap', xlabel='Chronological Age')\n",
    "ax.set_xlim(min_ - 0.5, max_ + 0.5)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Calculate and format correlation values\n",
    "rp_unadj_str = str(np.round(stats.pearsonr(tmp_df.y_true, tmp_df.unadj_BAG)[0], 2))\n",
    "rs_unadj_str = str(np.round(stats.spearmanr(tmp_df.y_true, tmp_df.unadj_BAG)[0], 2))\n",
    "\n",
    "rp_adj_str = str(np.round(stats.pearsonr(tmp_df.y_true, tmp_df.adj_BAG)[0], 2))\n",
    "rs_adj_str = str(np.round(stats.spearmanr(tmp_df.y_true, tmp_df.adj_BAG)[0], 2))\n",
    "\n",
    "# Add text boxes with regression info\n",
    "fig.text(0.15, 0.25,\n",
    "         'Unadjusted \\n'\n",
    "         f'y = {intercept_unadj} + {slope_unadj}x\\n'\n",
    "         f'$r_p$ = {rp_unadj_str}\\n'\n",
    "         f'$r_s$ = {rs_unadj_str}\\n',\n",
    "         va='top',\n",
    "         fontsize=10)\n",
    "\n",
    "fig.text(0.35, 0.25,\n",
    "         'Adjusted \\n'\n",
    "         f'y = {intercept_adj} + {slope_adj}x\\n'\n",
    "         f'$r_p$ = {rp_adj_str}\\n'\n",
    "         f'$r_s$ = {rs_adj_str}\\n',\n",
    "         va='top',\n",
    "         fontsize=10)\n",
    "\n",
    "# Set fontsize for labels\n",
    "ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig(os.path.join(result_dir_path, 'Figure_1D_BAG_for_patients.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE over all subjects\n",
    "overall_mae = mean_absolute_error(y_true=MCC_results_df.y_true.values, \n",
    "                                  y_pred=MCC_results_df.y_pred.values)\n",
    "print(f\"Overall MAE: {overall_mae:.2f}\")\n",
    "\n",
    "# Standardized MAE\n",
    "standardized_mae = overall_mae / np.std(HC_df.Age)\n",
    "print(f\"Standardized MAE: {standardized_mae:.2f}\")\n",
    "print()\n",
    "\n",
    "# Calculate SMAE separately for healthy controls\n",
    "sex = {0: 'males', 1: 'females'}\n",
    "\n",
    "for c, gender in sex.items():\n",
    "    print(f\"Healthy Controls - {gender}:\")\n",
    "    mask = HC_df.Sex == c\n",
    "    mae = mean_absolute_error(y_true=np.array(MCC_results_df.y_true.values)[mask], \n",
    "                              y_pred=np.array(MCC_results_df.y_pred.values)[mask])\n",
    "    smae = mae / np.std(HC_df.Age[mask])\n",
    "    print(f'MAE: {mae:.2f}')\n",
    "    print(f'SMAE: {smae:.2f}')\n",
    "    print()\n",
    "\n",
    "# Calculate SMAE separately for patients\n",
    "for c, gender in sex.items():\n",
    "    print(f\"Patients - {gender}:\")\n",
    "    mask = PT_df.Sex == c\n",
    "    mae = mean_absolute_error(y_true=np.array(predictions_patients_df.y_true.values)[mask], \n",
    "                              y_pred=np.array(predictions_patients_df.y_pred.values)[mask])\n",
    "    smae = mae / np.std(PT_df.Age[mask])\n",
    "    print(f'MAE: {mae:.2f}')\n",
    "    print(f'SMAE: {smae:.2f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject-wise probability of accelerated brain aging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate subject-wise probability of accelerated brain aging: first quantile containing true age of subject\n",
    "\n",
    "def calculate_quantile_indices_and_scores(df):\n",
    "    quantile_indices = []\n",
    "    alpha_scores = []\n",
    "    quantiles = [f'{frac:.3f}_aleatory_epistemic' for frac in np.arange(100 + 1) * 0.01]\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        quantile_idx = np.where(row[quantiles].values > row.y_true)[0]\n",
    "\n",
    "        if len(quantile_idx) == 0:\n",
    "            # Append 100 if BAG is negative, append 0 if BAG is positive\n",
    "            if row.adj_BAG > 0:\n",
    "                quantile_indices.append(0)\n",
    "                alpha_scores.append(50)\n",
    "            else:\n",
    "                quantile_indices.append(100)\n",
    "                alpha_scores.append(-50)\n",
    "        else:\n",
    "            quantile_idx = quantile_idx[0]\n",
    "            quantile_indices.append(quantile_idx)\n",
    "            quantile_idx = 50 - quantile_idx if quantile_idx < 50 else -1 * (quantile_idx - 50)\n",
    "            alpha_scores.append(quantile_idx)\n",
    "\n",
    "    df['quantile_indices'] = quantile_indices\n",
    "    df['alpha_scores'] = alpha_scores\n",
    "    df['alpha_p'] = (50 - df.quantile_indices) / 50\n",
    "    return df\n",
    "\n",
    "def get_extreme_bag_examples(df, N=1):\n",
    "    unique_alpha_scores = np.sort(df['alpha_scores'].unique())\n",
    "    highest_bag_scores = unique_alpha_scores[-N:]\n",
    "    lowest_bag_scores = unique_alpha_scores[:N]\n",
    "\n",
    "    highest_bag = df[df['alpha_scores'].isin(highest_bag_scores)]\n",
    "    lowest_bag = df[df['alpha_scores'].isin(lowest_bag_scores)]\n",
    "\n",
    "    highest_bag = highest_bag.groupby('alpha_scores').apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "    lowest_bag = lowest_bag.groupby('alpha_scores').apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "    \n",
    "    return highest_bag, lowest_bag\n",
    "\n",
    "# Calculate for patients\n",
    "predictions_patients_df = calculate_quantile_indices_and_scores(predictions_patients_df)\n",
    "highest_patient, lowest_patient = get_extreme_bag_examples(predictions_patients_df, 3)\n",
    "\n",
    "# Calculate for healthy controls\n",
    "MCC_results_df = calculate_quantile_indices_and_scores(MCC_results_df)\n",
    "highest_hc, lowest_hc = get_extreme_bag_examples(MCC_results_df, 3)\n",
    "\n",
    "# Printing example highest and lowest BAG for patients and healthy controls\n",
    "\n",
    "cols_to_print = ['0.000_aleatory_epistemic', '0.010_aleatory_epistemic', \n",
    "                 '0.990_aleatory_epistemic', '1.000_aleatory_epistemic', \n",
    "                 'y_pred', 'y_true', \n",
    "                 'adj_BAG', 'quantile_indices', 'alpha_scores', 'alpha_p']\n",
    "\n",
    "print(\"Example highest BAG for patients:\")\n",
    "print(display(highest_patient[cols_to_print]))\n",
    "print(\"\\n\\nExample lowest BAG for patients:\")\n",
    "print(display(lowest_patient[cols_to_print]))\n",
    "\n",
    "\n",
    "print(\"\\n\\nExample highest BAG for healthy controls:\")\n",
    "print(display(highest_hc[cols_to_print]))\n",
    "print(\"\\n\\nExample lowest BAG for healthy controls:\")\n",
    "print(display(lowest_hc[cols_to_print]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictionss\n",
    "predictions_patients_df['group'] = 'Anxiety Disorder'\n",
    "MCC_results_df['group'] = 'Healthy Control'\n",
    "combined_df = pd.concat([predictions_patients_df, MCC_results_df])\n",
    "\n",
    "# Calculate means for each group\n",
    "mean_patient = combined_df.loc[combined_df['group'] == 'Anxiety Disorder', 'adj_BAG'].mean()\n",
    "mean_control = combined_df.loc[combined_df['group'] == 'Healthy Control', 'adj_BAG'].mean()\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plot the KDE for both groups and fill the area under the curve\n",
    "sns.kdeplot(data=combined_df[combined_df['group'] == 'Anxiety Disorder'], \n",
    "            x='adj_BAG', fill=True, color='Red', alpha=0.4, label='Anxiety Disorder')\n",
    "sns.kdeplot(data=combined_df[combined_df['group'] == 'Healthy Control'], \n",
    "            x='adj_BAG', fill=True, color='Blue', alpha=0.4, label='Healthy Control')\n",
    "\n",
    "# Add vertical lines for the mean values\n",
    "plt.axvline(mean_patient, color='Red', linestyle='--', linewidth=1.5)  # Match color for patient group\n",
    "plt.axvline(mean_control, color='Blue', linestyle='--', linewidth=1.5)  # Match color for control group\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of BAG scores for Anxiety Disorder Patients and Healthy Controls')\n",
    "plt.xlabel('Uncertainty-Adjusted BAG')\n",
    "plt.ylabel('Density')\n",
    "# plt.legend(title='Group')  # Add legend to show mean lines\n",
    "\n",
    "plt.xlim(-2.5, 2.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data\n",
    "combined_df = pd.read_csv('BAG_residuals_per_group.csv')\n",
    "combined_df['group'] = combined_df['Dx'].map({0: 'Healthy Control', 1: 'Anxiety Disorder'})\n",
    "\n",
    "# Calculate means for each group\n",
    "mean_patient = combined_df.loc[combined_df['group'] == 'Anxiety Disorder', 'plot_res'].mean()\n",
    "mean_control = combined_df.loc[combined_df['group'] == 'Healthy Control', 'plot_res'].mean()\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plot the KDE for both groups and fill the area under the curve\n",
    "sns.kdeplot(data=combined_df[combined_df['group'] == 'Anxiety Disorder'], \n",
    "            x='plot_res', fill=True, color='Red', alpha=0.4, label='Anxiety Disorder')\n",
    "sns.kdeplot(data=combined_df[combined_df['group'] == 'Healthy Control'], \n",
    "            x='plot_res', fill=True, color='Blue', alpha=0.4, label='Healthy Control')\n",
    "\n",
    "# Add vertical lines for the mean values\n",
    "plt.axvline(mean_patient, color='Red', linestyle='--', linewidth=1.5)  # Match color for patient group\n",
    "plt.axvline(mean_control, color='Blue', linestyle='--', linewidth=1.5)  # Match color for control group\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of BAG scores for Anxiety Disorder Patients and Healthy Controls')\n",
    "plt.xlabel('Uncertainty-Adjusted BAG (residuals)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Group')  # Add legend to show mean lines\n",
    "\n",
    "plt.xlim(-2.5, 2.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occlusion sensitivity mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and variables\n",
    "occlusion_sensitivity_mapping_dir = os.path.join(result_dir_path, 'occlusion_sensitivity_mapping') \n",
    "\n",
    "occlusion_adj_BAG_patients_path = os.path.join(occlusion_sensitivity_mapping_dir, 'occlusion_adj_BAG_patients.npy')\n",
    "occlusion_median_aleatory_epistemic_patients_path = os.path.join(occlusion_sensitivity_mapping_dir, 'occlusion_median_aleatory_epistemic_patients.npy')\n",
    "occlusion_std_aleatory_epistemic_patients_path = os.path.join(occlusion_sensitivity_mapping_dir, 'occlusion_std_aleatory_epistemic_patients.npy')\n",
    "original_adj_BAG_patients_path = os.path.join(occlusion_sensitivity_mapping_dir, 'original_adj_BAG_patients.npy')\n",
    "predictions_patients_csv_path = os.path.join(occlusion_sensitivity_mapping_dir, 'predictions_patients.csv')\n",
    "\n",
    "# Check if results directory exists\n",
    "if all([os.path.exists(occlusion_adj_BAG_patients_path),\n",
    "        os.path.exists(occlusion_median_aleatory_epistemic_patients_path),\n",
    "        os.path.exists(occlusion_std_aleatory_epistemic_patients_path),\n",
    "        os.path.exists(original_adj_BAG_patients_path),\n",
    "        os.path.exists(predictions_patients_csv_path)]):\n",
    "    \n",
    "    print('Loading results')\n",
    "    \n",
    "    occlusion_adj_BAG_patients = np.load(occlusion_adj_BAG_patients_path, allow_pickle=True)\n",
    "    occlusion_median_aleatory_epistemic_patients = np.load(occlusion_median_aleatory_epistemic_patients_path, allow_pickle=True)\n",
    "    occlusion_std_aleatory_epistemic_patients = np.load(occlusion_std_aleatory_epistemic_patients_path, allow_pickle=True)\n",
    "    adj_BAG_pred_patients = np.load(original_adj_BAG_patients_path, allow_pickle=True)\n",
    "    predictions_patients_df = pd.read_csv(predictions_patients_csv_path)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Results directory does not exist, perform occlusion sensitivity mapping\n",
    "    print('Performing occlusion sensitivity mapping')\n",
    "    \n",
    "    # Calculate number of patients and number of features\n",
    "    N_patients, N_features = X_pt.shape\n",
    "    \n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(occlusion_sensitivity_mapping_dir):\n",
    "        os.makedirs(occlusion_sensitivity_mapping_dir)\n",
    "    \n",
    "    adj_BAG_pred_patients = predictions_patients_df.adj_BAG.values\n",
    "    \n",
    "    # Create occlusion FS data and initialize arrays for occlusion results\n",
    "    occlusion_FS_data_patients = np.repeat(X_pt[:, :, np.newaxis], N_features, axis=2)\n",
    "    occlusion_adj_BAG_patients = np.zeros((N_patients, N_features))\n",
    "    occlusion_median_aleatory_epistemic_patients = np.zeros_like(occlusion_adj_BAG_patients)\n",
    "    occlusion_std_aleatory_epistemic_patients = np.zeros_like(occlusion_adj_BAG_patients)\n",
    "    \n",
    "    # Perform occlusion sensitivity mapping\n",
    "    for occlusion_idx in np.arange(N_features):\n",
    "        occlusion_FS_data_patients[:, occlusion_idx, occlusion_idx] = 0 # Occlude ROI\n",
    "        tmp_y_pred = my_pipe.predict(occlusion_FS_data_patients[:, :, occlusion_idx])\n",
    "        tmp_adj_BAG = (tmp_y_pred['median_aleatory_epistemic'] - predictions_patients_df['y_true'] ) / tmp_y_pred['std_aleatory_epistemic']\n",
    "        \n",
    "        occlusion_adj_BAG_patients[:, occlusion_idx] = tmp_adj_BAG\n",
    "        occlusion_median_aleatory_epistemic_patients[:, occlusion_idx] = tmp_y_pred['median_aleatory_epistemic']\n",
    "        occlusion_std_aleatory_epistemic_patients[:, occlusion_idx] = tmp_y_pred['std_aleatory_epistemic']\n",
    "    \n",
    "    # Save results\n",
    "    np.save(occlusion_adj_BAG_patients_path, occlusion_adj_BAG_patients, allow_pickle=True)\n",
    "    np.save(occlusion_median_aleatory_epistemic_patients_path, occlusion_median_aleatory_epistemic_patients, allow_pickle=True)\n",
    "    np.save(occlusion_std_aleatory_epistemic_patients_path, occlusion_std_aleatory_epistemic_patients, allow_pickle=True)\n",
    "    np.save(original_adj_BAG_patients_path, adj_BAG_pred_patients, allow_pickle=True)\n",
    "    predictions_patients_df.to_csv(predictions_patients_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same for healthy controls\n",
    "\n",
    "occlusion_adj_BAG_HC_path = os.path.join(occlusion_sensitivity_mapping_dir, 'occlusion_adj_BAG_HC.npy')\n",
    "occlusion_median_aleatory_epistemic_HC_path = os.path.join(occlusion_sensitivity_mapping_dir, 'occlusion_median_aleatory_epistemic_HC.npy')\n",
    "occlusion_std_aleatory_epistemic_HC_path = os.path.join(occlusion_sensitivity_mapping_dir, 'occlusion_std_aleatory_epistemic_HC.npy')\n",
    "original_adj_BAG_HC_path = os.path.join(occlusion_sensitivity_mapping_dir, 'original_adj_BAG_HC.npy')\n",
    "predictions_HC_csv_path = os.path.join(occlusion_sensitivity_mapping_dir, 'predictions_HC.csv')\n",
    "\n",
    "# Check if results directory exists\n",
    "if all([os.path.exists(occlusion_adj_BAG_HC_path),\n",
    "        os.path.exists(occlusion_median_aleatory_epistemic_HC_path),\n",
    "        os.path.exists(occlusion_std_aleatory_epistemic_HC_path),\n",
    "        os.path.exists(original_adj_BAG_HC_path),\n",
    "        os.path.exists(predictions_HC_csv_path)]):\n",
    "    \n",
    "    print('Loading results')\n",
    "    \n",
    "    occlusion_adj_BAG_HC = np.load(occlusion_adj_BAG_HC_path, allow_pickle=True)\n",
    "    occlusion_median_aleatory_epistemic_HC = np.load(occlusion_median_aleatory_epistemic_HC_path, allow_pickle=True)\n",
    "    occlusion_std_aleatory_epistemic_HC = np.load(occlusion_std_aleatory_epistemic_HC_path, allow_pickle=True)\n",
    "    adj_BAG_pred_HC = np.load(original_adj_BAG_HC_path, allow_pickle=True)\n",
    "    MCC_results_df = pd.read_csv(predictions_HC_csv_path)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Results directory does not exist, perform occlusion sensitivity mapping\n",
    "    print('Performing occlusion sensitivity mapping')\n",
    "    \n",
    "    # Calculate number of HC and number of features\n",
    "    X_hc = HC_df[FS_cols].to_numpy()\n",
    "    N_HC, N_features = X_hc.shape\n",
    "    \n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(occlusion_sensitivity_mapping_dir):\n",
    "        os.makedirs(occlusion_sensitivity_mapping_dir)\n",
    "    \n",
    "    adj_BAG_pred_HC = MCC_results_df.adj_BAG.values\n",
    "    \n",
    "    # Create occlusion FS data and initialize arrays for occlusion results\n",
    "    occlusion_FS_data_HC = np.repeat(X_hc[:, :, np.newaxis], N_features, axis=2)\n",
    "    occlusion_adj_BAG_HC = np.zeros((N_HC, N_features))\n",
    "    occlusion_median_aleatory_epistemic_HC = np.zeros_like(occlusion_adj_BAG_HC)\n",
    "    occlusion_std_aleatory_epistemic_HC = np.zeros_like(occlusion_adj_BAG_HC)\n",
    "    \n",
    "    # Perform occlusion sensitivity mapping\n",
    "    for occlusion_idx in np.arange(N_features):\n",
    "        occlusion_FS_data_HC[:, occlusion_idx, occlusion_idx] = 0 # Occlude ROI\n",
    "        tmp_y_pred = my_pipe.predict(occlusion_FS_data_HC[:, :, occlusion_idx])\n",
    "        tmp_adj_BAG = (tmp_y_pred['median_aleatory_epistemic'] - MCC_results_df['y_true']) / tmp_y_pred['std_aleatory_epistemic']\n",
    "        \n",
    "        occlusion_adj_BAG_HC[:, occlusion_idx] = tmp_adj_BAG\n",
    "        occlusion_median_aleatory_epistemic_HC[:, occlusion_idx] = tmp_y_pred['median_aleatory_epistemic']\n",
    "        occlusion_std_aleatory_epistemic_HC[:, occlusion_idx] = tmp_y_pred['std_aleatory_epistemic']\n",
    "    \n",
    "    # Save results\n",
    "    np.save(occlusion_adj_BAG_HC_path, occlusion_adj_BAG_HC, allow_pickle=True)\n",
    "    np.save(occlusion_median_aleatory_epistemic_HC_path, occlusion_median_aleatory_epistemic_HC, allow_pickle=True)\n",
    "    np.save(occlusion_std_aleatory_epistemic_HC_path, occlusion_std_aleatory_epistemic_HC, allow_pickle=True)\n",
    "    np.save(original_adj_BAG_HC_path, adj_BAG_pred_HC, allow_pickle=True)\n",
    "    MCC_results_df.to_csv(predictions_HC_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store occlusion sensitivity data in long format for R studio analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe that includes all variables used to fit LME model. \n",
    "\n",
    "occlusion_adj_BAG_scores_df = pd.DataFrame(data=occlusion_adj_BAG_patients, columns=FS_cols)\n",
    "occlusion_adj_BAG_scores_df['no_occlusion'] = adj_BAG_pred_patients\n",
    "controlling_vars = PT_df[['SubjID', 'Age', 'Sex', 'MultiSiteID']].copy().reset_index()\n",
    "\n",
    "data_df = occlusion_adj_BAG_scores_df.join(controlling_vars)\n",
    "data_df = data_df.drop('index', axis=1)\n",
    "\n",
    "assert np.all(data_df.Age.values == y_pt)\n",
    "assert np.all(data_df.MultiSiteID.values == groups_pt)\n",
    "assert np.all(data_df.no_occlusion.values == adj_BAG_pred_patients)\n",
    "\n",
    "data_df = pd.melt(data_df, id_vars=['SubjID', 'Age', 'Sex', 'MultiSiteID'], \n",
    "                  value_vars=occlusion_adj_BAG_scores_df.columns.values,\n",
    "                  value_name='BAGz',\n",
    "                  var_name='region')\n",
    "\n",
    "\n",
    "long_data_csv_path = os.path.join(occlusion_sensitivity_mapping_dir, 'occlusion_data_long_MCCQRNN_Regressor.csv')\n",
    "data_df.to_csv(long_data_csv_path)\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for HC: load results - save as long format\n",
    "\n",
    "occlusion_adj_BAG_scores_df = pd.DataFrame(data=occlusion_adj_BAG_HC, columns=FS_cols)\n",
    "occlusion_adj_BAG_scores_df['no_occlusion'] = adj_BAG_pred_HC\n",
    "controlling_vars = HC_df[['SubjID', 'Age', 'Sex', 'MultiSiteID']].copy().reset_index()\n",
    "\n",
    "data_df = occlusion_adj_BAG_scores_df.join(controlling_vars)\n",
    "data_df = data_df.drop('index', axis=1)\n",
    "\n",
    "assert np.all(data_df.no_occlusion.values == adj_BAG_pred_HC)\n",
    "\n",
    "data_df = pd.melt(data_df, id_vars=['SubjID', 'Age', 'Sex', 'MultiSiteID'], \n",
    "                  value_vars=occlusion_adj_BAG_scores_df.columns.values,\n",
    "                  value_name='BAGz',\n",
    "                  var_name='region')\n",
    "\n",
    "\n",
    "long_data_csv_path = os.path.join(occlusion_sensitivity_mapping_dir, 'occlusion_data_HC_long_MCCQRNN_Regressor.csv')\n",
    "data_df.to_csv(long_data_csv_path)\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photon-ai",
   "language": "python",
   "name": "photon-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
